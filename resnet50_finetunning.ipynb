{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '/home/xiaojun/ssd_caffe/python')\n",
    "import caffe\n",
    "\n",
    "train_lmdb = '/home/xiaojun/kaggle/dog-breed-identification/dataset/train_lmdb'\n",
    "val_lmdb = '/home/xiaojun/kaggle/dog-breed-identification/dataset/val_lmdb'\n",
    "\n",
    "dataset_dir = 'dataset/'\n",
    "label_file = dataset_dir + 'labels.csv'\n",
    "train_set = dataset_dir + 'train/'\n",
    "test_set = dataset_dir + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label size: 10222\n",
      "training images: 10222\n",
      "test images: 10357\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(label_file):\n",
    "    df_csv = pd.read_csv(label_file)\n",
    "else:\n",
    "    print label_file, 'does not exist'\n",
    "\n",
    "label_list = df_csv.as_matrix()\n",
    "print 'label size: {}'.format(label_list.shape[0])\n",
    "\n",
    "train_images = os.listdir(train_set)\n",
    "print 'training images: {}'.format(len(train_images))\n",
    "\n",
    "test_images = os.listdir(test_set)\n",
    "print 'test images: {}'.format(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breed size: 120\n"
     ]
    }
   ],
   "source": [
    "#convert training dataset to lmdb\n",
    "\n",
    "#create category.txt\n",
    "breed = df_csv.loc[:, 'breed'].as_matrix()\n",
    "unique_label = np.unique(breed)\n",
    "print 'breed size: {}'.format(len(unique_label))\n",
    "with open(dataset_dir + 'category.txt', 'w') as f:\n",
    "    for item in unique_label:\n",
    "        f.write(item + '\\n')\n",
    "        \n",
    "#split labels.csv to train.txt and val.txt\n",
    "NUM_TRAIN = int(np.floor(label_list.shape[0] * 0.8))\n",
    "NUM_VAL = int(label_list.shape[0] - NUM_TRAIN)\n",
    "\n",
    "df_txt = df_csv.copy()\n",
    "for i in df_txt.index:\n",
    "    df_txt.loc[i, 'id'] = str(train_set + df_csv.loc[i, 'id'] + '.jpg')\n",
    "    df_txt.loc[i, 'breed'] = int(np.argwhere(unique_label == df_csv.loc[i, 'breed']))\n",
    "\n",
    "labels = df_txt.as_matrix()\n",
    "train_labels = labels[:NUM_TRAIN]\n",
    "val_labels = labels[NUM_TRAIN:]\n",
    "\n",
    "with open(dataset_dir + 'train.txt', 'w') as f:\n",
    "    for item in train_labels:\n",
    "        f.write(item[0] + ' ' + str(item[1]) + '\\n')\n",
    "        \n",
    "with open(dataset_dir + 'val.txt', 'w') as f:\n",
    "    for item in val_labels:\n",
    "        f.write(item[0] + ' ' + str(item[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define resnet50\n",
    "from caffe import layers as L, params as P\n",
    "\n",
    "def conv_bn_scale_relu(in_blob, num_output, kernel_size, stride, pad, mode, bias_term=False):\n",
    "    conv = L.Convolution(in_blob, num_output=num_output, kernel_size=kernel_size, stride=stride, pad=pad,\n",
    "                         bias_term=bias_term,\n",
    "                         param=dict(lr_mult=0, decay_mult=1))\n",
    "    if mode == 'train':\n",
    "        bn = L.BatchNorm(conv, use_global_stats=False, in_place=True)\n",
    "    else:\n",
    "        bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    scale = L.Scale(bn, bias_term=True, in_place=True)\n",
    "    relu = L.ReLU(scale, in_place=True)\n",
    "    return conv, bn, scale, relu\n",
    "\n",
    "def conv_bn_scale(in_blob, num_output, kernel_size, stride, pad, mode, bias_term=False):\n",
    "    conv = L.Convolution(in_blob, num_output=num_output, kernel_size=kernel_size, stride=stride, pad=pad,\n",
    "                         bias_term=bias_term,\n",
    "                         param=dict(lr_mult=0, decay_mult=1))\n",
    "    if mode == 'train':\n",
    "        bn = L.BatchNorm(conv, use_global_stats=False, in_place=True)\n",
    "    else:\n",
    "        bn = L.BatchNorm(conv, use_global_stats=True, in_place=True)\n",
    "    scale = L.Scale(bn, bias_term=True, in_place=True)\n",
    "    return conv, bn, scale\n",
    "\n",
    "def conv_block(in_blob, kernel_num, stage, mode):\n",
    "    if stage == 2:\n",
    "        conv1, bn1, scale1 = conv_bn_scale(in_blob, kernel_num[2], 1, 1, 0, mode)\n",
    "    else:\n",
    "        conv1, bn1, scale1 = conv_bn_scale(in_blob, kernel_num[2], 1, 2, 0, mode)\n",
    "    conv2a, bn2a, scale2a, relu2a = conv_bn_scale_relu(in_blob, kernel_num[0], 1, 1, 0, mode)\n",
    "    if stage == 2:\n",
    "        conv2b, bn2b, scale2b, relu2b = conv_bn_scale_relu(relu2a, kernel_num[1], 3, 1, 1, mode)\n",
    "    else:\n",
    "        conv2b, bn2b, scale2b, relu2b = conv_bn_scale_relu(relu2a, kernel_num[1], 3, 2, 1, mode)\n",
    "    conv2c, bn2c, scale2c = conv_bn_scale(relu2b, kernel_num[2], 1, 1, 0, mode) \n",
    "    wise = L.Eltwise(scale2c, scale1, operation=P.Eltwise.SUM)\n",
    "    relu = L.ReLU(wise, in_place=True)\n",
    "    return conv1, bn1, scale1, conv2a, bn2a, scale2a, relu2a, conv2b, bn2b, scale2b, relu2b, conv2c, bn2c, scale2c, wise, relu\n",
    "\n",
    "def identity_block(in_blob, kernel_num, mode):\n",
    "    conv2a, bn2a, scale2a, relu2a = conv_bn_scale_relu(in_blob, kernel_num[0], 1, 1, 0, mode)\n",
    "    conv2b, bn2b, scale2b, relu2b = conv_bn_scale_relu(relu2a, kernel_num[1], 3, 1, 1, mode)\n",
    "    conv2c, bn2c, scale2c = conv_bn_scale(relu2b, kernel_num[2], 1, 1, 0, mode)\n",
    "    wise = L.Eltwise(scale2c, in_blob, operation=P.Eltwise.SUM)\n",
    "    relu = L.ReLU(wise, in_place=True)\n",
    "    return conv2a, bn2a, scale2a, relu2a, conv2b, bn2b, scale2b, relu2b, conv2c, bn2c, scale2c, wise, relu\n",
    "\n",
    "def resnet50_net(mode, train_data=None, val_data=None, train_batchsize=0, val_batchsize=0):\n",
    "    n = caffe.NetSpec()\n",
    "    kernel_num_list = [[64, 64, 256], [128, 128, 512], [256, 256, 1024], [512, 512, 2048]] # kernel num of stage2/3/4/5\n",
    "    block_num_list = [3, 4, 6, 3] # block num of stage2/3/4/5\n",
    "    block_list = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "    \n",
    "    if mode == 'train':\n",
    "        n.data, n.label = L.Data(name='data', source=train_data, batch_size=train_batchsize, backend=P.Data.LMDB, ntop=2,\n",
    "                                 include=dict(phase=caffe.TRAIN),\n",
    "                                 transform_param=dict(mirror=True, mean_value=[104, 117, 123], crop_size=224))\n",
    "        train_data_layer_str = str(n.to_proto())\n",
    "    \n",
    "        n.data, n.label = L.Data(name='data', source=val_data, batch_size=val_batchsize, backend=P.Data.LMDB, ntop=2,\n",
    "                                 include=dict(phase=caffe.TEST),\n",
    "                                 transform_param=dict(mirror=False, mean_value=[104, 117, 123], crop_size=224))\n",
    "    elif mode == 'deploy':\n",
    "        n.data = L.Input(shape=dict(dim=[1, 3, 224, 224]))\n",
    "    else:\n",
    "        print 'Error: unknown mode'\n",
    "\n",
    "    #stage 1\n",
    "    conv_name = 'conv1'\n",
    "    bn_name = 'bn_conv1'\n",
    "    scale_name = 'scale_conv1'\n",
    "    relu_name = 'conv1_relu'\n",
    "    \n",
    "    n.__dict__['tops'][conv_name], n.__dict__['tops'][bn_name], \\\n",
    "    n.__dict__['tops'][scale_name], n.__dict__['tops'][relu_name] \\\n",
    "    = conv_bn_scale_relu(n.data, num_output=64, kernel_size=7, stride=2, pad=3, mode=mode, bias_term=True)\n",
    "    \n",
    "    n.pool1 = L.Pooling(n.__dict__['tops'][relu_name], pool=P.Pooling.MAX, kernel_size=3, stride=2)\n",
    "    \n",
    "    bottom = n.pool1\n",
    "    \n",
    "    #stage 2/3/4/5\n",
    "    for s in xrange(4):       \n",
    "        for i in xrange(block_num_list[s]):\n",
    "            conv_name = 'res' + str(s+2) + block_list[i] + '_branch'\n",
    "            bn_name = 'bn' + str(s+2) + block_list[i] + '_branch'\n",
    "            scale_name = 'scale' + str(s+2) + block_list[i] + '_branch'\n",
    "            wise_name = 'res' + str(s+2) + block_list[i]\n",
    "            relu_name = 'res' + str(s+2) + block_list[i] + '_relu'\n",
    "\n",
    "            if i == 0:\n",
    "                n.__dict__['tops'][conv_name+'1'], n.__dict__['tops'][bn_name+'1'], \\\n",
    "                n.__dict__['tops'][scale_name+'1'], n.__dict__['tops'][conv_name+'2a'], \\\n",
    "                n.__dict__['tops'][bn_name+'2a'], n.__dict__['tops'][scale_name+'2a'], \\\n",
    "                n.__dict__['tops'][conv_name+'2a_relu'], \\\n",
    "                n.__dict__['tops'][conv_name+'2b'], n.__dict__['tops'][bn_name+'2b'], \\\n",
    "                n.__dict__['tops'][scale_name+'2b'], n.__dict__['tops'][conv_name+'2b_relu'], \\\n",
    "                n.__dict__['tops'][conv_name+'2c'], n.__dict__['tops'][bn_name+'2c'], \\\n",
    "                n.__dict__['tops'][scale_name+'2c'],  \\\n",
    "                n.__dict__['tops'][wise_name], n.__dict__['tops'][relu_name] \\\n",
    "                = conv_block(bottom, kernel_num_list[s], s+2, mode)\n",
    "            else:\n",
    "                n.__dict__['tops'][conv_name+'2a'], n.__dict__['tops'][bn_name+'2a'], \\\n",
    "                n.__dict__['tops'][scale_name+'2a'], n.__dict__['tops'][conv_name+'2a_relu'], \\\n",
    "                n.__dict__['tops'][conv_name+'2b'], n.__dict__['tops'][bn_name+'2b'], \\\n",
    "                n.__dict__['tops'][scale_name+'2b'], n.__dict__['tops'][conv_name+'2b_relu'], \\\n",
    "                n.__dict__['tops'][conv_name+'2c'], n.__dict__['tops'][bn_name+'2c'], \\\n",
    "                n.__dict__['tops'][scale_name+'2c'], n.__dict__['tops'][wise_name], \\\n",
    "                n.__dict__['tops'][relu_name] \\\n",
    "                = identity_block(bottom, kernel_num_list[s], mode)\n",
    "\n",
    "            bottom = n.__dict__['tops'][relu_name]\n",
    "    \n",
    "    #average pooling and fc layer\n",
    "    n.pool5 = L.Pooling(bottom, pool=P.Pooling.AVE, kernel_size=7, stride=1)\n",
    "    n.fc120 = L.InnerProduct(n.pool5, num_output=120, weight_filler=dict(type='xavier'), bias_filler=dict(type='constant'))\n",
    "    if mode == 'train':\n",
    "        n.loss = L.SoftmaxWithLoss(n.fc120, n.label, include=dict(phase=caffe.TRAIN))\n",
    "        n.accuracy1 = L.Accuracy(n.fc120, n.label, top_k=1, include=dict(phase=caffe.TEST))\n",
    "        n.accuracy5 = L.Accuracy(n.fc120, n.label, top_k=5, include=dict(phase=caffe.TEST))\n",
    "        return 'name: \"DogNet-ResNet50\"\\n' + train_data_layer_str + str(n.to_proto())\n",
    "    elif mode == 'deploy':\n",
    "        n.prob = L.Softmax(n.fc120)\n",
    "        return 'name: \"DogNet-ResNet50\"\\n' + str(n.to_proto())\n",
    "    else:\n",
    "        print 'Error: unknown mode'\n",
    "        \n",
    "with open('resnet50/resnet50_train_val.prototxt', 'w') as f:\n",
    "    net_spec_str = resnet50_net(mode='train', train_data=train_lmdb, val_data=val_lmdb, train_batchsize=16, val_batchsize=8)\n",
    "    f.write(net_spec_str)\n",
    "with open ('resnet50/resnet50_deploy.prototxt', 'w') as f:\n",
    "    net_spec_str = resnet50_net(mode='deploy')\n",
    "    f.write(net_spec_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define solver.prototxt\n",
    "def create_solver():\n",
    "    solver = caffe.proto.caffe_pb2.SolverParameter()\n",
    "    solver.net = \"resnet50_train_val.prototxt\"\n",
    "    solver.test_iter.append(250)\n",
    "    solver.test_interval = 500\n",
    "#    solver.average_loss = 40\n",
    "#    solver.test_initialization = false\n",
    "    solver.type = 'SGD'\n",
    "    solver.base_lr = 0.001\n",
    "    solver.lr_policy = \"step\"\n",
    "    solver.gamma = 0.1\n",
    "    solver.stepsize = 1000\n",
    "    solver.momentum = 0.9\n",
    "    solver.weight_decay = 0.0005\n",
    "    solver.display = 100\n",
    "    solver.max_iter = 4000\n",
    "    solver.snapshot = 1000\n",
    "    solver.solver_mode = P.Solver.GPU\n",
    "    solver.snapshot_prefix = \"snapshot_resnet50\"\n",
    "    return solver\n",
    "\n",
    "with open(\"resnet50/resnet50_solver.prototxt\", \"w\") as f:\n",
    "    f.write(str(create_solver()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finetune resnet50\n",
    "weights = '/home/intel/models/caffemodels/resnet/ResNet-50-model.caffemodel'\n",
    "solver_file = 'resnet50/resnet50_solver.prototxt'\n",
    "\n",
    "niter = 100\n",
    "caffe.set_mode_cpu()\n",
    "\n",
    "solver = caffe.get_solver(solver_file)\n",
    "solver.net.copy_from(weights)\n",
    "\n",
    "for iter in xrange(niter):\n",
    "    solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy1': array(0.625, dtype=float32),\n",
       " 'accuracy5': array(1., dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "\n",
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image\n",
    "\n",
    "trained_weights = '/home/xiaojun/kaggle/dog-breed-identification/snapshot_resnet50_iter_4000.caffemodel'\n",
    "net = caffe.Net('resnet50/resnet50_train_val.prototxt', trained_weights, caffe.TEST)\n",
    "net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_net = caffe.Net('resnet50/resnet50_deploy.prototxt', trained_weights, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on testset\n",
    "import numpy as np\n",
    "mean_file = '/home/xiaojun/kaggle/dog-breed-identification/dataset/ilsvrc_2012_mean.npy'\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': deploy_net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.load(mean_file).mean(1).mean(1))\n",
    "transformer.set_raw_scale('data', 255)\n",
    "transformer.set_channel_swap('data', (2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "image_list = os.listdir(test_set)\n",
    "num_test_image = len(image_list)\n",
    "result_df = pd.DataFrame(columns=unique_label)\n",
    "file_name_list = []\n",
    "\n",
    "for i in xrange(num_test_image):\n",
    "    image_path = test_set + image_list[i]\n",
    "    image = caffe.io.load_image(image_path)\n",
    "    transformed_image = transformer.preprocess('data', image)\n",
    "    deploy_net.blobs['data'].data[...] = transformed_image\n",
    "    deploy_net.forward()\n",
    "    prob = deploy_net.blobs['prob'].data[0]\n",
    "    #out = deploy_net.blobs['prob'].data[0].argmax()\n",
    "    file_name, ext = os.path.splitext(image_list[i])\n",
    "    file_name_list.append(file_name)\n",
    "    \n",
    "    item = pd.Series(np.array(prob), index=unique_label)\n",
    "    result_df = result_df.append(item, ignore_index=True)\n",
    "\n",
    "fn_df = pd.DataFrame(file_name_list, columns=['id'])\n",
    "result_df = pd.concat([fn_df, result_df], axis=1)\n",
    "\n",
    "result_df.to_csv('resnet50_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
